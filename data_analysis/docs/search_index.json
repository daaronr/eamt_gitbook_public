[["index.html", "EA Market testing data analysis About 0.1 Tech and collophon", " EA Market testing data analysis About See ‘Effective Giving &amp; Action: Market testing &amp; Synthesis’ - public and private version 0.1 Tech and collophon This is styled based on the Rethink Priorities ‘Bookdown template’ … and you may wish to manually update from there Note that this is a ‘bookdown site in the gitbook style.’ However, we’re not sure yet if and how it can be integrated with the https://app.gitbook.com/. Note this is currently in the same github repo as the related https://app.gitbook.com/ project linked above. "],["tlycs-portland-trial-background-data-input-brief-report.html", "1 TLYCS Portland trial: background, data input, brief report 1.1 The trial 1.2 Capturing data 1.3 Input and clean data 1.4 Exploratory analysis 1.5 Casual/simple ‘uptick’ analysis", " 1 TLYCS Portland trial: background, data input, brief report 1.1 The trial In December 2021, TLYCS ran a YouTube advertising campaign in single city, involving ‘donation advice.’ The top 10% household income households were targeted with (one of?) three categories of videos. The details are presented in our (currently private) gitbook HERE 1.2 Capturing data I (David Reinstein) did a manual ‘create report and download’ in TLYCS google analytics, basically as described here The report and it’s parameters can be accessed here, if you have access. Report: 3-31 December 2021 vs prior year, same dates All North American cities with 1 or more user Counts: Users, sessions, certain types of conversions (see below) I downloaded this as an Excel spreadsheet effective_giving_market_testing/data_do_not_commit/tlycs/tlycs_dec_2021_vs_2020_by_city_n_america_pos_users.xlsx (This is gitignored so it won’t be ‘committed’ to our repo, at least for now) 1.3 Input and clean data #tl21 &lt;- read_excel(here::here(&quot;data_do_not_commit&quot;, &quot;tlycs&quot;, &quot;tlycs_dec_2021_vs_2020_by_city_n_america.xlsx&quot;), sheet = &quot;Dataset1&quot;) #this should have worked? tl21 &lt;- readxl::read_excel(&quot;~/githubs/effective_giving_market_testing/data_do_not_commit/tlycs/tlycs_dec_2021_vs_2020_by_city_n_america.xlsx&quot;, sheet = &quot;Dataset1&quot;) %&gt;% as_tibble() Create ‘year’ feature tl21 &lt;- tl21 %&gt;% mutate( year = case_when( str_detect(`Date Range`, &quot;2021&quot;) == TRUE ~ 2021, str_detect(`Date Range`, &quot;2020&quot;) == TRUE ~ 2020 ) ) Create ‘differences across years’ features. Need to re-label the ‘correct’ Portland (we think), as this is a common city name.1 tl21 %&gt;% filter(City==&quot;Portland&quot;) %&gt;% dplyr::select(City, year, Users) ## # A tibble: 6 × 3 ## City year Users ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Portland 2021 1 ## 2 Portland 2020 0 ## 3 Portland 2021 8 ## 4 Portland 2020 6 ## 5 Portland 2021 306 ## 6 Portland 2020 144 Presumably the largest one is Portland Oregon, and we’ll relable it as such. tl21 &lt;- tl21 %&gt;% mutate( City = case_when(City==&quot;Portland&quot; &amp; Users&gt;20 ~ &quot;Portland_OR&quot;, City==&quot;Portland&quot; ~ &quot;Other_Portland&quot;, TRUE ~ City) ) 1.4 Exploratory analysis 1.5 Casual/simple ‘uptick’ analysis tl21 %&gt;% sumtab(Users, year) Table 1.1: year N share &gt; 0 Mean Median P80 Std.dev. 2020 4923 0.701 7.42 1 3 (260.96) 2021 4923 0.745 9.45 1 4 (332.7) tl21 %&gt;% filter(!City==&quot;Portland_OR&quot;) %&gt;% sumtab(Users, year) Table 1.1: year N share &gt; 0 Mean Median P80 Std.dev. 2020 4921 0.701 3.68 1 3 (20.94) 2021 4921 0.745 4.66 1 4 (28.22) tl21 %&gt;% filter(Users&gt;20) %&gt;% sumtab(Users, year) #Fix -- filter on over 20 users for 2020 ONLY] Table 1.1: year N share &gt; 0 Mean Median P80 Std.dev. 2020 111 1 242.86 42.0 111.0 (1729.02) 2021 140 1 259.26 42.5 113.4 (1963.27) tl21 %&gt;% sumtab(Sessions, year) Table 1.1: year N share &gt; 0 Mean Median P80 Std.dev. 2020 4923 0.701 9.25 1 4 (325.58) 2021 4923 0.745 11.75 1 4 (413.48) OR_users_21 &lt;- tl21 %&gt;% dplyr::filter(City==&quot;Portland_OR&quot; &amp; year==2021) %&gt;% select(&#39;Users&#39;) %&gt;% pull() OR_users_20 &lt;- tl21 %&gt;% dplyr::filter(City==&quot;Portland_OR&quot; &amp; year==2020) %&gt;% select(&#39;Users&#39;) %&gt;% pull() OR_uptick &lt;- OR_users_21 - OR_users_20 nonOR &lt;- tl21 %&gt;% dplyr::filter(City!=&quot;Portland_OR&quot;) %&gt;% select(&#39;Users&#39;, year) nonOR_users_21 &lt;- mean(nonOR$Users[nonOR$year==2021]) nonOR_users_20 &lt;- mean(nonOR$Users[nonOR$year==2020]) nonOR_uptick &lt;- (nonOR_users_21 - nonOR_users_20)/nonOR_users_20 (As in interactive Gitbook) 1.5.1 Difference in Differences comparison to other cities Guiding assumptions: the cities used are fairly representative ‘uptick as a percentage’ is unrelated to city size/visits last year all the cities in the comparison group are ‘informative to the counterfactual’ in proportion to their total number of sessions (I’m waving the hands a bit here) Thus 112.5% visits uptick (YoY) for Portland in 2020 For ’all North American cities other than Portland (with positive users in either year): The average is 3.68 users in the 2020 period and 4.66 users in the 2021 period, an uptick of 4.66 - 3.68)/3.68 = about 26.8%. 26.8% uptick \\(\\times\\) 144 = 38.5 ‘counterfactual uptic’ in users for Portland 162 -38.5 = 123 ‘uptick relative to counterfactual’ or_uptick_vs_cfl &lt;- OR_users_21 - OR_users_20 - nonOR_uptick*OR_users_20 USD 4000 /123 = USD 32.4 cost per user This seems realistic at a first-pass (but it may be better to focus on a narrower comparison group) And there are two other ‘Portlands,’ each with a small number of sessions↩︎ "],["oftw-pre-giving-tuesday-email-upselling-split-test-impact-vs-emotion.html", "2 OftW pre-giving-tuesday-email upselling split test (impact vs emotion) 2.1 The trial 2.2 Capturing data 2.3 Input and clean data 2.4 Descriptives and exploratory analysis 2.5 Basic tests: Donation incidence and amounts 2.6 Basic tests: Clicks and retention outcomes 2.7 “Equivalence testing” with randomization inference/simulation", " 2 OftW pre-giving-tuesday-email upselling split test (impact vs emotion) 2.1 The trial In December 2021, OftW sent out a sequence of emails to existing OftW pledgers/participants asking them for an additional donation. There were two ‘treatment variants’; an emotional email and a standard impact-based email. The treatment was constant by individual (the same person always got emails with the same theme. The details are presented in our (currently private) gitbook HERE and in the linked pre-registration (also on OSF). 2.2 Capturing data Kennan and Chloe captured the data and Metadata from The OFTW database SurveyMonkey Putting this into the (private) Google sheet linked HERE We added some metadata/explainers to that data, and downloaded it as an Excel sheet.2 … 2.3 Input and clean data gs4_auth(scope = &quot;https://www.googleapis.com/auth/drive&quot;) ## ℹ Suitable tokens found in the cache, associated with these emails: ## • &#39;daaronr@gmail.com&#39; ## • &#39;dreinstein@rethinkpriorities.org&#39; ## Defaulting to the first email. ## ! Using an auto-discovered, cached token. ## To suppress this message, modify your code or options to clearly consent to the use of a ## cached token. ## See gargle&#39;s &quot;Non-interactive auth&quot; vignette for more details: ## &lt;https://gargle.r-lib.org/articles/non-interactive-auth.html&gt; ## ℹ The googlesheets4 package is using a cached token for &#39;daaronr@gmail.com&#39;. drive_auth(token = gs4_token()) oftw_ppl_don_21_22 &lt;- read_sheet(&quot;https://docs.google.com/spreadsheets/d/1iUKXkEqoadBgtUG_epBzUzCgA_J5mdWWstcXtpAdNJs/edit#gid=521638649&quot;, sheet=&quot;Raw data (Mailchimp)&quot;) %&gt;% select(-`Treatment group`) #remove an un-useful repeated name column ## ✓ Reading from &quot;November GivingTuesday Email Series Test_opened_contacts&quot;. ## ✓ Range &#39;&#39;Raw data (Mailchimp)&#39;&#39;. oftw_ppl_don_21_22 %&gt;% names() %&gt;% paste(collapse=&quot;, &quot;) ## [1] &quot;Email Address, sheet_descriptor, First Name, Last Name, Treatment Group, Email Date, Email Number, Class Year, Donor status, Total Given, Donation amount, Donation frequency, Start string, Platform, Portfolio string, Class lead, Impact 1, Impact 2, Impact 3, Employer, Pledge string, School string, Pledge year, Cancellation Type, Donation Amount String, OFTW matching, OFTW match amount, Corporate match amount, Bonuses announced, Post-bonus contact date, Email Preferences, Start Date, Lives Saved, Member Rating, Opens, Donate link clicks, Record rank, Total Giving Season contributions, Total Giving Season contribution amount&quot; … 2.3.1 Labeling and cleaning Make names snake_case, use original names as labels: labelled::var_label(oftw_ppl_don_21_22) &lt;- names(oftw_ppl_don_21_22) names(oftw_ppl_don_21_22) &lt;- snakecase::to_snake_case(names(oftw_ppl_don_21_22)) Separate second row (descriptors) from tibble: oftw_ppl_don_21_22_col_descriptors &lt;- oftw_ppl_don_21_22[1,] oftw_ppl_don_21_22 &lt;- oftw_ppl_don_21_22[-c(1),] Anonymize it: oftw_ppl_don_21_22 &lt;- oftw_ppl_don_21_22 %&gt;% dplyr::select(-first_name, -last_name) %&gt;% mutate(email_address= salt(.seed = 42, email_address) %&gt;% hash(.algo = &quot;crc32&quot;), school_string= salt(.seed = 43, school_string) %&gt;% hash(.algo = &quot;crc32&quot;), employer= salt(.seed = 44, employer) %&gt;% hash(.algo = &quot;crc32&quot;) ) 2.4 Descriptives and exploratory analysis 2.5 Basic tests: Donation incidence and amounts (See preregistration – go through preregistered tests one at a time) 2.6 Basic tests: Clicks and retention outcomes 2.7 “Equivalence testing” with randomization inference/simulation (Reprise/merge in analysis done HERE) Todo – more direct input through API tools.↩︎ "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
